{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f8772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c42d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = pd.read_csv('train1.csv')\n",
    "df_test1 = pd.read_csv('test1.csv')\n",
    "\n",
    "df_train2 = pd.read_csv('train2.csv')\n",
    "df_test2 = pd.read_csv('test2.csv')\n",
    "\n",
    "df_train3 = pd.read_csv('train3.csv')\n",
    "df_test3 = pd.read_csv('test3.csv')\n",
    "\n",
    "df_train4 = pd.read_csv('train4.csv')\n",
    "df_test4 = pd.read_csv('test4.csv')\n",
    "\n",
    "# df_train5 = pd.read_csv('train6.csv')\n",
    "# df_test5 = pd.read_csv('test6.csv')\n",
    "\n",
    "# df_train = pd.merge(df_train1, df_train2, on=['sn', 'fault_time', 'label'])\\\n",
    "#     .merge(df_train3, on=['sn', 'fault_time', 'label'])\\\n",
    "#     .merge(df_train4, on=['sn', 'fault_time', 'label'])\\\n",
    "#     .merge(df_train5, on=['sn', 'fault_time', 'label'])\n",
    "# df_test = pd.merge(df_test1, df_test2, on=['sn', 'fault_time'])\\\n",
    "#     .merge(df_test3, on=['sn', 'fault_time'])\\\n",
    "#     .merge(df_test4, on=['sn', 'fault_time'])\\\n",
    "#     .merge(df_test5, on=['sn', 'fault_time'])\n",
    "\n",
    "df_train = pd.merge(df_train1, df_train2, on=['sn', 'fault_time', 'label'])\\\n",
    "    .merge(df_train3, on=['sn', 'fault_time', 'label'])\\\n",
    "    .merge(df_train4, on=['sn', 'fault_time', 'label'])\n",
    "df_test = pd.merge(df_test1, df_test2, on=['sn', 'fault_time'])\\\n",
    "    .merge(df_test3, on=['sn', 'fault_time'])\\\n",
    "    .merge(df_test4, on=['sn', 'fault_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c5f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train = pd.read_csv('../bert/train.csv')\n",
    "bert_test = pd.read_csv('../bert/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40972ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, bert_train.iloc[:, 9:]], axis=1)\n",
    "df_test = pd.concat([df_test, bert_test.iloc[:, 9:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76922f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16604, 1610), (3011, 1609))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3273675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(y_true, y_pred) -> float:\n",
    "    \"\"\"\n",
    "    计算得分\n",
    "    :param target_df: [sn,fault_time,label]\n",
    "    :param submit_df: [sn,fault_time,label]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    weights =  [3  /  7,  2  /  7,  1  /  7,  1  /  7]\n",
    "    overall_df = pd.DataFrame([y_true, y_pred]).T\n",
    "    overall_df.columns = ['label_gt', 'label_pr']\n",
    "\n",
    "    macro_F1 =  0.\n",
    "    for i in  range(len(weights)):\n",
    "        TP =  len(overall_df[(overall_df['label_gt'] == i) & (overall_df['label_pr'] == i)])\n",
    "        FP =  len(overall_df[(overall_df['label_gt'] != i) & (overall_df['label_pr'] == i)])\n",
    "        FN =  len(overall_df[(overall_df['label_gt'] == i) & (overall_df['label_pr'] != i)])\n",
    "        precision = TP /  (TP + FP)  if  (TP + FP)  >  0  else  0\n",
    "        recall = TP /  (TP + FN)  if  (TP + FP)  >  0  else  0\n",
    "        F1 =  2  * precision * recall /  (precision + recall)  if  (precision + recall)  >  0  else  0\n",
    "        macro_F1 += weights[i]  * F1\n",
    "    return macro_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1268405",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = df_train['label'].nunique()\n",
    "FOLDS = 10\n",
    "TARGET = 'label'\n",
    "use_features = [col for col in df_train.columns if col not in ['sn', 'fault_time', TARGET]]\n",
    "\n",
    "def run_ctb(df_train, df_test, use_features):\n",
    "    target = TARGET\n",
    "    oof_pred = np.zeros((len(df_train), NUM_CLASSES))\n",
    "    y_pred = np.zeros((len(df_test), NUM_CLASSES))\n",
    "    \n",
    "    folds = GroupKFold(n_splits=FOLDS)\n",
    "    for fold, (tr_ind, val_ind) in enumerate(folds.split(df_train, df_train[TARGET], df_train['sn'])):\n",
    "        print(f'Fold {fold + 1}')\n",
    "        x_train, x_val = df_train[use_features].iloc[tr_ind], df_train[use_features].iloc[val_ind] \n",
    "        y_train, y_val = df_train[target].iloc[tr_ind], df_train[target].iloc[val_ind]\n",
    "\n",
    "        params_ = {\n",
    "            'objective': 'multi:softmax',\n",
    "            'eta': 0.03,\n",
    "            'max_depth': 7,\n",
    "            'subsample': 0.8,\n",
    "            'n_estimators': 10000,\n",
    "            'reg_alpha': 5,\n",
    "            'reg_lambda': 5,\n",
    "            'min_child_weight': 16,\n",
    "            'tree_method': 'gpu_hist'\n",
    "        }\n",
    "        model = xgb.XGBClassifier(max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    verbosity=0,\n",
    "    silent=None,\n",
    "    objective=\"multi:softmax\",\n",
    "    booster='gbtree',\n",
    "    n_jobs=-1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=None,)\n",
    "        model.fit(x_train, y_train, early_stopping_rounds=100,\n",
    "                  eval_set=[(x_train, y_train), (x_val, y_val)], eval_metric='mlogloss',\n",
    "                  verbose=100)\n",
    "        \n",
    "        oof_pred[val_ind] = model.predict_proba(x_val) \n",
    "        y_pred += model.predict_proba(df_test[use_features]) / folds.n_splits\n",
    "        \n",
    "        score = f1_score(y_val, oof_pred[val_ind].argmax(axis=1), average='macro')\n",
    "        print(f'F1 score: {score}')\n",
    "        \n",
    "        print(\"Features importance...\")\n",
    "        feat_imp = pd.DataFrame({'imp': model.feature_importances_, 'feature': use_features})\n",
    "        feat_imp.sort_values(by='imp').to_csv('%d_imp.csv'%fold, index=False)\n",
    "        print(feat_imp.sort_values(by='imp').reset_index(drop=True))\n",
    "        \n",
    "        del x_train, x_val, y_train, y_val\n",
    "        gc.collect()\n",
    "        \n",
    "    return y_pred, oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2523da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "[0]\tvalidation_0-mlogloss:1.24464\tvalidation_1-mlogloss:1.25377\n",
      "[100]\tvalidation_0-mlogloss:0.09761\tvalidation_1-mlogloss:0.38160\n",
      "[170]\tvalidation_0-mlogloss:0.06332\tvalidation_1-mlogloss:0.40490\n",
      "F1 score: 0.7278551740259316\n",
      "Features importance...\n",
      "           imp      feature\n",
      "0     0.000000   msg_id_711\n",
      "1     0.000000   msg_id_713\n",
      "2     0.000000   msg_id_712\n",
      "3     0.000000   msg_id_710\n",
      "4     0.000000   msg_id_709\n",
      "...        ...          ...\n",
      "1602  0.026250   msg_w2v_44\n",
      "1603  0.029278    msg_id_80\n",
      "1604  0.037468    msg_id_57\n",
      "1605  0.048526           11\n",
      "1606  0.049227  max_proba_0\n",
      "\n",
      "[1607 rows x 2 columns]\n",
      "Fold 2\n",
      "[0]\tvalidation_0-mlogloss:1.24596\tvalidation_1-mlogloss:1.25419\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23680/2605113932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ctb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_23680/4197447486.py\u001b[0m in \u001b[0;36mrun_ctb\u001b[0;34m(df_train, df_test, use_features)\u001b[0m\n\u001b[1;32m     50\u001b[0m         model.fit(x_train, y_train, early_stopping_rounds=100,\n\u001b[1;32m     51\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mlogloss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                   verbose=100)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0moof_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/projects/log-based-failuer-diagnosis/env/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/projects/log-based-failuer-diagnosis/env/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         )\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/projects/log-based-failuer-diagnosis/env/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/projects/log-based-failuer-diagnosis/env/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/projects/log-based-failuer-diagnosis/env/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred, oof_pred = run_ctb(df_train, df_test, use_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d741193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(macro_f1(df_train[TARGET], np.argmax(oof_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a663d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.read_csv('../data/preliminary_submit_dataset_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09ece9dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21938/789242146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fault_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "sub = submit_df[['sn', 'fault_time']].copy()\n",
    "sub['label'] = y_pred.argmax(axis=1)\n",
    "display(sub.head())\n",
    "print(sub['label'].value_counts() / sub.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13cf8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('baseline3_gkf_sn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc32f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = pd.read_csv('../data/preliminary_train_label_dataset.csv')\n",
    "label2 = pd.read_csv('../data/preliminary_train_label_dataset_s.csv')\n",
    "label_df = pd.concat([label1, label2]).reset_index(drop=True)\n",
    "label_df = label_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(label_df['label'].value_counts() / label_df.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
