{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9286b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea38f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.read_csv('./data/preliminary_submit_dataset_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511eb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = pd.read_csv('./data/preliminary_train_label_dataset.csv')\n",
    "label2 = pd.read_csv('./data/preliminary_train_label_dataset_s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e5d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.concat([label1, label2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce8e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_df = pd.read_csv('./data/preliminary_sel_log_dataset.csv')\n",
    "test_log_df = pd.read_csv('./data/preliminary_sel_log_dataset_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424e37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.concat([train_log_df, test_log_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b16687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' System Boot Initiated BIOS_Boot_Up ', ' State Asserted ', ' Asserted']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df['msg'].values[0].split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763236e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9480885",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_msg_list = []\n",
    "for sn, group in log_df.groupby('sn'):\n",
    "    group = group.sort_values(by='time')\n",
    "    tail_msg_list.append('.'.join(group['msg'].tail(10).to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cfb198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sent = [word_tokenize(s.lower()) for s in tail_msg_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5a983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_sent)]\n",
    "model = Doc2Vec(tagged_data, vector_size=64, window=2, min_count=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f33ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_feature(df):\n",
    "    if df.shape[0] <= 1:\n",
    "        return [df.shape[0], np.nan, np.nan, np.nan, np.nan]\n",
    "    times = pd.to_datetime(df['time'])\n",
    "    time_diffs = (times.diff() / np.timedelta64(1, 's')).values[1:]\n",
    "    return [df.shape[0], np.mean(time_diffs), np.max(time_diffs), np.min(time_diffs), np.sum(time_diffs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3756427",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = []\n",
    "train_label = []\n",
    "model_feature = []\n",
    "time_feature = []\n",
    "for sn, group in train_log_df.groupby('sn'):\n",
    "    group = group.sort_values(by='time')\n",
    "    sub_label_df = label_df[label_df['sn'] == sn]\n",
    "    for item in sub_label_df.values:\n",
    "        label = item[0]\n",
    "        fault_time = item[1]\n",
    "        label = item[2]\n",
    "        sub_df = group[group['time'] <= fault_time].tail(10)\n",
    "        time_feature.append(get_time_feature(sub_df))\n",
    "        if sub_df.shape[0] > 0:\n",
    "            model_feature.append(int(sub_df['server_model'].values[0][2:]))\n",
    "        else:\n",
    "            model_feature.append(np.nan)\n",
    "        train_feature.append(model.infer_vector(word_tokenize('. s'.join(sub_df['msg']).lower())))\n",
    "        train_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c068913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16669, 64) (16669,) (16669, 5) (16669,)\n"
     ]
    }
   ],
   "source": [
    "train_feature = np.array(train_feature)\n",
    "model_feature = np.array(model_feature)\n",
    "time_feature = np.array(time_feature)\n",
    "train_label = np.array(train_label)\n",
    "print(train_feature.shape, model_feature.shape, time_feature.shape, train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edd642ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = np.concatenate([train_feature, model_feature.reshape((model_feature.shape[0], 1))], axis=1)\n",
    "train_feature = np.concatenate([train_feature, time_feature], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972d9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_log_df = test_log_df.sort_values(by='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61f9c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "model_feature = []\n",
    "time_feature = []\n",
    "for i, row in submit_df.iterrows():\n",
    "    sub_df = test_log_df[(test_log_df['sn']==row['sn'])&(test_log_df['time']<=row['fault_time'])].tail(10)\n",
    "    time_feature.append(get_time_feature(sub_df))\n",
    "    if sub_df.shape[0] > 0:\n",
    "        model_feature.append(int(sub_df['server_model'].values[0][2:]))\n",
    "    else:\n",
    "        model_feature.append(np.nan)\n",
    "    test_data.append(model.infer_vector(word_tokenize('. '.join(sub_df['msg']).lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a81217a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3011, 70)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature = np.array(test_data)\n",
    "model_feature = np.array(model_feature)\n",
    "time_feature = np.array(time_feature)\n",
    "\n",
    "test_feature = np.concatenate([test_feature, model_feature.reshape((model_feature.shape[0], 1))], axis=1)\n",
    "test_feature = np.concatenate([test_feature, time_feature], axis=1)\n",
    "test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95fdcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(y_true, y_pred) -> float:\n",
    "    \"\"\"\n",
    "    计算得分\n",
    "    :param target_df: [sn,fault_time,label]\n",
    "    :param submit_df: [sn,fault_time,label]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    weights =  [3  /  7,  2  /  7,  1  /  7,  1  /  7]\n",
    "    overall_df = pd.DataFrame([y_true, y_pred]).T\n",
    "    overall_df.columns = ['label_gt', 'label_pr']\n",
    "\n",
    "    macro_F1 =  0.\n",
    "    for i in  range(len(weights)):\n",
    "        TP =  len(overall_df[(overall_df['label_gt'] == i) & (overall_df['label_pr'] == i)])\n",
    "        FP =  len(overall_df[(overall_df['label_gt'] != i) & (overall_df['label_pr'] == i)])\n",
    "        FN =  len(overall_df[(overall_df['label_gt'] == i) & (overall_df['label_pr'] != i)])\n",
    "        precision = TP /  (TP + FP)  if  (TP + FP)  >  0  else  0\n",
    "        recall = TP /  (TP + FN)  if  (TP + FP)  >  0  else  0\n",
    "        F1 =  2  * precision * recall /  (precision + recall)  if  (precision + recall)  >  0  else  0\n",
    "        macro_F1 += weights[i]  * F1\n",
    "    return macro_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19b1727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "877f9816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/projects/log-based-failuer-diagnosis/env/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17432\n",
      "[LightGBM] [Info] Number of data points in the train set: 13335, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score -2.424031\n",
      "[LightGBM] [Info] Start training from score -1.593813\n",
      "[LightGBM] [Info] Start training from score -0.578828\n",
      "[LightGBM] [Info] Start training from score -1.912359\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's multi_logloss: 0.961539\tvalid_1's multi_logloss: 0.983434\n",
      "[20]\ttraining's multi_logloss: 0.846718\tvalid_1's multi_logloss: 0.887026\n",
      "[30]\ttraining's multi_logloss: 0.764388\tvalid_1's multi_logloss: 0.82073\n",
      "[40]\ttraining's multi_logloss: 0.702164\tvalid_1's multi_logloss: 0.772603\n",
      "[50]\ttraining's multi_logloss: 0.652227\tvalid_1's multi_logloss: 0.737861\n",
      "[60]\ttraining's multi_logloss: 0.610253\tvalid_1's multi_logloss: 0.709654\n",
      "[70]\ttraining's multi_logloss: 0.574908\tvalid_1's multi_logloss: 0.687979\n",
      "[80]\ttraining's multi_logloss: 0.54425\tvalid_1's multi_logloss: 0.671843\n",
      "[90]\ttraining's multi_logloss: 0.516699\tvalid_1's multi_logloss: 0.658658\n",
      "[100]\ttraining's multi_logloss: 0.492456\tvalid_1's multi_logloss: 0.648224\n",
      "[110]\ttraining's multi_logloss: 0.470248\tvalid_1's multi_logloss: 0.639091\n",
      "[120]\ttraining's multi_logloss: 0.450021\tvalid_1's multi_logloss: 0.631968\n",
      "[130]\ttraining's multi_logloss: 0.431463\tvalid_1's multi_logloss: 0.625987\n",
      "[140]\ttraining's multi_logloss: 0.414086\tvalid_1's multi_logloss: 0.620695\n",
      "[150]\ttraining's multi_logloss: 0.397958\tvalid_1's multi_logloss: 0.616653\n",
      "[160]\ttraining's multi_logloss: 0.382998\tvalid_1's multi_logloss: 0.612862\n",
      "[170]\ttraining's multi_logloss: 0.368984\tvalid_1's multi_logloss: 0.609498\n",
      "[180]\ttraining's multi_logloss: 0.355902\tvalid_1's multi_logloss: 0.606824\n",
      "[190]\ttraining's multi_logloss: 0.343555\tvalid_1's multi_logloss: 0.604489\n",
      "[200]\ttraining's multi_logloss: 0.331936\tvalid_1's multi_logloss: 0.602631\n",
      "[210]\ttraining's multi_logloss: 0.320893\tvalid_1's multi_logloss: 0.600653\n",
      "[220]\ttraining's multi_logloss: 0.310337\tvalid_1's multi_logloss: 0.599201\n",
      "[230]\ttraining's multi_logloss: 0.300613\tvalid_1's multi_logloss: 0.597718\n",
      "[240]\ttraining's multi_logloss: 0.29114\tvalid_1's multi_logloss: 0.596755\n",
      "[250]\ttraining's multi_logloss: 0.282098\tvalid_1's multi_logloss: 0.596343\n",
      "[260]\ttraining's multi_logloss: 0.273323\tvalid_1's multi_logloss: 0.595802\n",
      "[270]\ttraining's multi_logloss: 0.265279\tvalid_1's multi_logloss: 0.59501\n",
      "[280]\ttraining's multi_logloss: 0.257414\tvalid_1's multi_logloss: 0.593972\n",
      "[290]\ttraining's multi_logloss: 0.249589\tvalid_1's multi_logloss: 0.593192\n",
      "[300]\ttraining's multi_logloss: 0.242145\tvalid_1's multi_logloss: 0.592486\n",
      "[310]\ttraining's multi_logloss: 0.234806\tvalid_1's multi_logloss: 0.592101\n",
      "[320]\ttraining's multi_logloss: 0.227953\tvalid_1's multi_logloss: 0.591745\n",
      "[330]\ttraining's multi_logloss: 0.221155\tvalid_1's multi_logloss: 0.591114\n",
      "[340]\ttraining's multi_logloss: 0.214823\tvalid_1's multi_logloss: 0.590422\n",
      "[350]\ttraining's multi_logloss: 0.208738\tvalid_1's multi_logloss: 0.590446\n",
      "[360]\ttraining's multi_logloss: 0.202847\tvalid_1's multi_logloss: 0.590047\n",
      "[370]\ttraining's multi_logloss: 0.196981\tvalid_1's multi_logloss: 0.589952\n",
      "[380]\ttraining's multi_logloss: 0.191515\tvalid_1's multi_logloss: 0.590103\n",
      "Early stopping, best iteration is:\n",
      "[362]\ttraining's multi_logloss: 0.201612\tvalid_1's multi_logloss: 0.5899\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17431\n",
      "[LightGBM] [Info] Number of data points in the train set: 13335, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score -2.424031\n",
      "[LightGBM] [Info] Start training from score -1.593813\n",
      "[LightGBM] [Info] Start training from score -0.578828\n",
      "[LightGBM] [Info] Start training from score -1.912359\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's multi_logloss: 0.959751\tvalid_1's multi_logloss: 0.98951\n",
      "[20]\ttraining's multi_logloss: 0.843414\tvalid_1's multi_logloss: 0.894476\n",
      "[30]\ttraining's multi_logloss: 0.760995\tvalid_1's multi_logloss: 0.831848\n",
      "[40]\ttraining's multi_logloss: 0.698219\tvalid_1's multi_logloss: 0.785734\n",
      "[50]\ttraining's multi_logloss: 0.649044\tvalid_1's multi_logloss: 0.752794\n",
      "[60]\ttraining's multi_logloss: 0.607559\tvalid_1's multi_logloss: 0.72602\n",
      "[70]\ttraining's multi_logloss: 0.572248\tvalid_1's multi_logloss: 0.705137\n",
      "[80]\ttraining's multi_logloss: 0.541169\tvalid_1's multi_logloss: 0.687966\n",
      "[90]\ttraining's multi_logloss: 0.513993\tvalid_1's multi_logloss: 0.674252\n",
      "[100]\ttraining's multi_logloss: 0.48961\tvalid_1's multi_logloss: 0.662632\n",
      "[110]\ttraining's multi_logloss: 0.467819\tvalid_1's multi_logloss: 0.65326\n",
      "[120]\ttraining's multi_logloss: 0.447574\tvalid_1's multi_logloss: 0.645226\n",
      "[130]\ttraining's multi_logloss: 0.429087\tvalid_1's multi_logloss: 0.638287\n",
      "[140]\ttraining's multi_logloss: 0.412026\tvalid_1's multi_logloss: 0.632358\n",
      "[150]\ttraining's multi_logloss: 0.395894\tvalid_1's multi_logloss: 0.627779\n",
      "[160]\ttraining's multi_logloss: 0.38127\tvalid_1's multi_logloss: 0.623654\n",
      "[170]\ttraining's multi_logloss: 0.367137\tvalid_1's multi_logloss: 0.620347\n",
      "[180]\ttraining's multi_logloss: 0.354074\tvalid_1's multi_logloss: 0.617957\n",
      "[190]\ttraining's multi_logloss: 0.341826\tvalid_1's multi_logloss: 0.616167\n",
      "[200]\ttraining's multi_logloss: 0.330128\tvalid_1's multi_logloss: 0.614686\n",
      "[210]\ttraining's multi_logloss: 0.319347\tvalid_1's multi_logloss: 0.612841\n",
      "[220]\ttraining's multi_logloss: 0.308925\tvalid_1's multi_logloss: 0.611426\n",
      "[230]\ttraining's multi_logloss: 0.298933\tvalid_1's multi_logloss: 0.610342\n",
      "[240]\ttraining's multi_logloss: 0.289442\tvalid_1's multi_logloss: 0.609521\n",
      "[250]\ttraining's multi_logloss: 0.280226\tvalid_1's multi_logloss: 0.608454\n",
      "[260]\ttraining's multi_logloss: 0.271662\tvalid_1's multi_logloss: 0.607904\n",
      "[270]\ttraining's multi_logloss: 0.263567\tvalid_1's multi_logloss: 0.607631\n",
      "[280]\ttraining's multi_logloss: 0.255477\tvalid_1's multi_logloss: 0.606794\n",
      "[290]\ttraining's multi_logloss: 0.247783\tvalid_1's multi_logloss: 0.606276\n",
      "[300]\ttraining's multi_logloss: 0.240437\tvalid_1's multi_logloss: 0.605554\n",
      "[310]\ttraining's multi_logloss: 0.233597\tvalid_1's multi_logloss: 0.605734\n",
      "[320]\ttraining's multi_logloss: 0.226494\tvalid_1's multi_logloss: 0.605331\n",
      "[330]\ttraining's multi_logloss: 0.220098\tvalid_1's multi_logloss: 0.60506\n",
      "[340]\ttraining's multi_logloss: 0.213573\tvalid_1's multi_logloss: 0.604541\n",
      "[350]\ttraining's multi_logloss: 0.207325\tvalid_1's multi_logloss: 0.60429\n",
      "[360]\ttraining's multi_logloss: 0.201378\tvalid_1's multi_logloss: 0.603975\n",
      "[370]\ttraining's multi_logloss: 0.195665\tvalid_1's multi_logloss: 0.603773\n",
      "[380]\ttraining's multi_logloss: 0.190091\tvalid_1's multi_logloss: 0.603883\n",
      "[390]\ttraining's multi_logloss: 0.184504\tvalid_1's multi_logloss: 0.60359\n",
      "[400]\ttraining's multi_logloss: 0.179202\tvalid_1's multi_logloss: 0.60346\n",
      "[410]\ttraining's multi_logloss: 0.17406\tvalid_1's multi_logloss: 0.603129\n",
      "[420]\ttraining's multi_logloss: 0.169002\tvalid_1's multi_logloss: 0.603037\n",
      "[430]\ttraining's multi_logloss: 0.164111\tvalid_1's multi_logloss: 0.603013\n",
      "[440]\ttraining's multi_logloss: 0.159271\tvalid_1's multi_logloss: 0.603006\n",
      "Early stopping, best iteration is:\n",
      "[425]\ttraining's multi_logloss: 0.166395\tvalid_1's multi_logloss: 0.602609\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17432\n",
      "[LightGBM] [Info] Number of data points in the train set: 13335, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score -2.424031\n",
      "[LightGBM] [Info] Start training from score -1.593444\n",
      "[LightGBM] [Info] Start training from score -0.578962\n",
      "[LightGBM] [Info] Start training from score -1.912359\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's multi_logloss: 0.959536\tvalid_1's multi_logloss: 0.984702\n",
      "[20]\ttraining's multi_logloss: 0.843139\tvalid_1's multi_logloss: 0.889265\n",
      "[30]\ttraining's multi_logloss: 0.761553\tvalid_1's multi_logloss: 0.824303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\ttraining's multi_logloss: 0.699566\tvalid_1's multi_logloss: 0.776746\n",
      "[50]\ttraining's multi_logloss: 0.650105\tvalid_1's multi_logloss: 0.742736\n",
      "[60]\ttraining's multi_logloss: 0.609409\tvalid_1's multi_logloss: 0.716355\n",
      "[70]\ttraining's multi_logloss: 0.574809\tvalid_1's multi_logloss: 0.694578\n",
      "[80]\ttraining's multi_logloss: 0.544365\tvalid_1's multi_logloss: 0.67657\n",
      "[90]\ttraining's multi_logloss: 0.518067\tvalid_1's multi_logloss: 0.662229\n",
      "[100]\ttraining's multi_logloss: 0.49339\tvalid_1's multi_logloss: 0.650131\n",
      "[110]\ttraining's multi_logloss: 0.471063\tvalid_1's multi_logloss: 0.639487\n",
      "[120]\ttraining's multi_logloss: 0.451\tvalid_1's multi_logloss: 0.631567\n",
      "[130]\ttraining's multi_logloss: 0.43276\tvalid_1's multi_logloss: 0.624528\n",
      "[140]\ttraining's multi_logloss: 0.415695\tvalid_1's multi_logloss: 0.618723\n",
      "[150]\ttraining's multi_logloss: 0.399571\tvalid_1's multi_logloss: 0.613372\n",
      "[160]\ttraining's multi_logloss: 0.384735\tvalid_1's multi_logloss: 0.609676\n",
      "[170]\ttraining's multi_logloss: 0.370672\tvalid_1's multi_logloss: 0.606174\n",
      "[180]\ttraining's multi_logloss: 0.357543\tvalid_1's multi_logloss: 0.602878\n",
      "[190]\ttraining's multi_logloss: 0.345257\tvalid_1's multi_logloss: 0.599793\n",
      "[200]\ttraining's multi_logloss: 0.333787\tvalid_1's multi_logloss: 0.597406\n",
      "[210]\ttraining's multi_logloss: 0.322738\tvalid_1's multi_logloss: 0.594995\n",
      "[220]\ttraining's multi_logloss: 0.312364\tvalid_1's multi_logloss: 0.592843\n",
      "[230]\ttraining's multi_logloss: 0.302592\tvalid_1's multi_logloss: 0.591474\n",
      "[240]\ttraining's multi_logloss: 0.293351\tvalid_1's multi_logloss: 0.590187\n",
      "[250]\ttraining's multi_logloss: 0.284219\tvalid_1's multi_logloss: 0.589072\n",
      "[260]\ttraining's multi_logloss: 0.275617\tvalid_1's multi_logloss: 0.588197\n",
      "[270]\ttraining's multi_logloss: 0.267275\tvalid_1's multi_logloss: 0.587574\n",
      "[280]\ttraining's multi_logloss: 0.259299\tvalid_1's multi_logloss: 0.586594\n",
      "[290]\ttraining's multi_logloss: 0.251601\tvalid_1's multi_logloss: 0.585833\n",
      "[300]\ttraining's multi_logloss: 0.244171\tvalid_1's multi_logloss: 0.584985\n",
      "[310]\ttraining's multi_logloss: 0.236838\tvalid_1's multi_logloss: 0.584214\n",
      "[320]\ttraining's multi_logloss: 0.229852\tvalid_1's multi_logloss: 0.58364\n",
      "[330]\ttraining's multi_logloss: 0.223189\tvalid_1's multi_logloss: 0.583122\n",
      "[340]\ttraining's multi_logloss: 0.216731\tvalid_1's multi_logloss: 0.582569\n",
      "[350]\ttraining's multi_logloss: 0.210487\tvalid_1's multi_logloss: 0.582184\n",
      "[360]\ttraining's multi_logloss: 0.204607\tvalid_1's multi_logloss: 0.581903\n",
      "[370]\ttraining's multi_logloss: 0.198622\tvalid_1's multi_logloss: 0.581469\n",
      "[380]\ttraining's multi_logloss: 0.192819\tvalid_1's multi_logloss: 0.580983\n",
      "[390]\ttraining's multi_logloss: 0.187221\tvalid_1's multi_logloss: 0.580369\n",
      "[400]\ttraining's multi_logloss: 0.181501\tvalid_1's multi_logloss: 0.579916\n",
      "[410]\ttraining's multi_logloss: 0.176124\tvalid_1's multi_logloss: 0.58011\n",
      "[420]\ttraining's multi_logloss: 0.170905\tvalid_1's multi_logloss: 0.57969\n",
      "[430]\ttraining's multi_logloss: 0.166083\tvalid_1's multi_logloss: 0.579765\n",
      "[440]\ttraining's multi_logloss: 0.1613\tvalid_1's multi_logloss: 0.579751\n",
      "[450]\ttraining's multi_logloss: 0.156812\tvalid_1's multi_logloss: 0.579614\n",
      "[460]\ttraining's multi_logloss: 0.152401\tvalid_1's multi_logloss: 0.579544\n",
      "Early stopping, best iteration is:\n",
      "[449]\ttraining's multi_logloss: 0.157216\tvalid_1's multi_logloss: 0.579464\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17432\n",
      "[LightGBM] [Info] Number of data points in the train set: 13335, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score -2.424878\n",
      "[LightGBM] [Info] Start training from score -1.593444\n",
      "[LightGBM] [Info] Start training from score -0.578962\n",
      "[LightGBM] [Info] Start training from score -1.911851\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's multi_logloss: 0.961339\tvalid_1's multi_logloss: 0.983698\n",
      "[20]\ttraining's multi_logloss: 0.846424\tvalid_1's multi_logloss: 0.886957\n",
      "[30]\ttraining's multi_logloss: 0.764612\tvalid_1's multi_logloss: 0.821651\n",
      "[40]\ttraining's multi_logloss: 0.703937\tvalid_1's multi_logloss: 0.777227\n",
      "[50]\ttraining's multi_logloss: 0.654163\tvalid_1's multi_logloss: 0.741978\n",
      "[60]\ttraining's multi_logloss: 0.612922\tvalid_1's multi_logloss: 0.714477\n",
      "[70]\ttraining's multi_logloss: 0.577165\tvalid_1's multi_logloss: 0.692593\n",
      "[80]\ttraining's multi_logloss: 0.546795\tvalid_1's multi_logloss: 0.675494\n",
      "[90]\ttraining's multi_logloss: 0.519545\tvalid_1's multi_logloss: 0.659861\n",
      "[100]\ttraining's multi_logloss: 0.495522\tvalid_1's multi_logloss: 0.6483\n",
      "[110]\ttraining's multi_logloss: 0.473584\tvalid_1's multi_logloss: 0.638516\n",
      "[120]\ttraining's multi_logloss: 0.453377\tvalid_1's multi_logloss: 0.629714\n",
      "[130]\ttraining's multi_logloss: 0.435123\tvalid_1's multi_logloss: 0.623444\n",
      "[140]\ttraining's multi_logloss: 0.41764\tvalid_1's multi_logloss: 0.617338\n",
      "[150]\ttraining's multi_logloss: 0.401516\tvalid_1's multi_logloss: 0.612664\n",
      "[160]\ttraining's multi_logloss: 0.386623\tvalid_1's multi_logloss: 0.607982\n",
      "[170]\ttraining's multi_logloss: 0.372727\tvalid_1's multi_logloss: 0.604106\n",
      "[180]\ttraining's multi_logloss: 0.35941\tvalid_1's multi_logloss: 0.600561\n",
      "[190]\ttraining's multi_logloss: 0.347319\tvalid_1's multi_logloss: 0.597931\n",
      "[200]\ttraining's multi_logloss: 0.335763\tvalid_1's multi_logloss: 0.59485\n",
      "[210]\ttraining's multi_logloss: 0.324824\tvalid_1's multi_logloss: 0.592493\n",
      "[220]\ttraining's multi_logloss: 0.314119\tvalid_1's multi_logloss: 0.589999\n",
      "[230]\ttraining's multi_logloss: 0.304263\tvalid_1's multi_logloss: 0.588162\n",
      "[240]\ttraining's multi_logloss: 0.294764\tvalid_1's multi_logloss: 0.586313\n",
      "[250]\ttraining's multi_logloss: 0.285303\tvalid_1's multi_logloss: 0.58444\n",
      "[260]\ttraining's multi_logloss: 0.276942\tvalid_1's multi_logloss: 0.583592\n",
      "[270]\ttraining's multi_logloss: 0.268562\tvalid_1's multi_logloss: 0.582392\n",
      "[280]\ttraining's multi_logloss: 0.260355\tvalid_1's multi_logloss: 0.58135\n",
      "[290]\ttraining's multi_logloss: 0.252751\tvalid_1's multi_logloss: 0.5806\n",
      "[300]\ttraining's multi_logloss: 0.245166\tvalid_1's multi_logloss: 0.580209\n",
      "[310]\ttraining's multi_logloss: 0.237986\tvalid_1's multi_logloss: 0.579675\n",
      "[320]\ttraining's multi_logloss: 0.230782\tvalid_1's multi_logloss: 0.579272\n",
      "[330]\ttraining's multi_logloss: 0.224188\tvalid_1's multi_logloss: 0.578939\n",
      "[340]\ttraining's multi_logloss: 0.217697\tvalid_1's multi_logloss: 0.578803\n",
      "[350]\ttraining's multi_logloss: 0.211503\tvalid_1's multi_logloss: 0.578214\n",
      "[360]\ttraining's multi_logloss: 0.205442\tvalid_1's multi_logloss: 0.577971\n",
      "[370]\ttraining's multi_logloss: 0.19958\tvalid_1's multi_logloss: 0.577992\n",
      "[380]\ttraining's multi_logloss: 0.193975\tvalid_1's multi_logloss: 0.577553\n",
      "[390]\ttraining's multi_logloss: 0.188755\tvalid_1's multi_logloss: 0.577023\n",
      "[400]\ttraining's multi_logloss: 0.183502\tvalid_1's multi_logloss: 0.576936\n",
      "[410]\ttraining's multi_logloss: 0.178504\tvalid_1's multi_logloss: 0.577088\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttraining's multi_logloss: 0.184459\tvalid_1's multi_logloss: 0.576756\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17432\n",
      "[LightGBM] [Info] Number of data points in the train set: 13336, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score -2.424106\n",
      "[LightGBM] [Info] Start training from score -1.593519\n",
      "[LightGBM] [Info] Start training from score -0.579037\n",
      "[LightGBM] [Info] Start training from score -1.911926\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's multi_logloss: 0.959158\tvalid_1's multi_logloss: 0.99054\n",
      "[20]\ttraining's multi_logloss: 0.840682\tvalid_1's multi_logloss: 0.897201\n",
      "[30]\ttraining's multi_logloss: 0.757392\tvalid_1's multi_logloss: 0.835493\n",
      "[40]\ttraining's multi_logloss: 0.695774\tvalid_1's multi_logloss: 0.791809\n",
      "[50]\ttraining's multi_logloss: 0.64624\tvalid_1's multi_logloss: 0.75859\n",
      "[60]\ttraining's multi_logloss: 0.604306\tvalid_1's multi_logloss: 0.73274\n",
      "[70]\ttraining's multi_logloss: 0.569073\tvalid_1's multi_logloss: 0.711148\n",
      "[80]\ttraining's multi_logloss: 0.538486\tvalid_1's multi_logloss: 0.693562\n",
      "[90]\ttraining's multi_logloss: 0.511555\tvalid_1's multi_logloss: 0.67977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 0.487037\tvalid_1's multi_logloss: 0.668956\n",
      "[110]\ttraining's multi_logloss: 0.464874\tvalid_1's multi_logloss: 0.660082\n",
      "[120]\ttraining's multi_logloss: 0.444531\tvalid_1's multi_logloss: 0.652107\n",
      "[130]\ttraining's multi_logloss: 0.42588\tvalid_1's multi_logloss: 0.646491\n",
      "[140]\ttraining's multi_logloss: 0.408557\tvalid_1's multi_logloss: 0.641475\n",
      "[150]\ttraining's multi_logloss: 0.392517\tvalid_1's multi_logloss: 0.636885\n",
      "[160]\ttraining's multi_logloss: 0.37766\tvalid_1's multi_logloss: 0.633011\n",
      "[170]\ttraining's multi_logloss: 0.363947\tvalid_1's multi_logloss: 0.629544\n",
      "[180]\ttraining's multi_logloss: 0.350778\tvalid_1's multi_logloss: 0.626634\n",
      "[190]\ttraining's multi_logloss: 0.338829\tvalid_1's multi_logloss: 0.624098\n",
      "[200]\ttraining's multi_logloss: 0.327591\tvalid_1's multi_logloss: 0.622887\n",
      "[210]\ttraining's multi_logloss: 0.316761\tvalid_1's multi_logloss: 0.621473\n",
      "[220]\ttraining's multi_logloss: 0.30655\tvalid_1's multi_logloss: 0.62007\n",
      "[230]\ttraining's multi_logloss: 0.296752\tvalid_1's multi_logloss: 0.618582\n",
      "[240]\ttraining's multi_logloss: 0.287351\tvalid_1's multi_logloss: 0.617251\n",
      "[250]\ttraining's multi_logloss: 0.278481\tvalid_1's multi_logloss: 0.615808\n",
      "[260]\ttraining's multi_logloss: 0.269831\tvalid_1's multi_logloss: 0.614824\n",
      "[270]\ttraining's multi_logloss: 0.261541\tvalid_1's multi_logloss: 0.613894\n",
      "[280]\ttraining's multi_logloss: 0.253452\tvalid_1's multi_logloss: 0.612904\n",
      "[290]\ttraining's multi_logloss: 0.245717\tvalid_1's multi_logloss: 0.611931\n",
      "[300]\ttraining's multi_logloss: 0.23824\tvalid_1's multi_logloss: 0.611467\n",
      "[310]\ttraining's multi_logloss: 0.230991\tvalid_1's multi_logloss: 0.610766\n",
      "[320]\ttraining's multi_logloss: 0.224137\tvalid_1's multi_logloss: 0.610315\n",
      "[330]\ttraining's multi_logloss: 0.217318\tvalid_1's multi_logloss: 0.609561\n",
      "[340]\ttraining's multi_logloss: 0.21089\tvalid_1's multi_logloss: 0.608849\n",
      "[350]\ttraining's multi_logloss: 0.204416\tvalid_1's multi_logloss: 0.608324\n",
      "[360]\ttraining's multi_logloss: 0.198404\tvalid_1's multi_logloss: 0.608029\n",
      "[370]\ttraining's multi_logloss: 0.192386\tvalid_1's multi_logloss: 0.607388\n",
      "[380]\ttraining's multi_logloss: 0.186652\tvalid_1's multi_logloss: 0.607125\n",
      "[390]\ttraining's multi_logloss: 0.181299\tvalid_1's multi_logloss: 0.606872\n",
      "[400]\ttraining's multi_logloss: 0.175828\tvalid_1's multi_logloss: 0.606481\n",
      "[410]\ttraining's multi_logloss: 0.170522\tvalid_1's multi_logloss: 0.606351\n",
      "[420]\ttraining's multi_logloss: 0.16543\tvalid_1's multi_logloss: 0.606298\n",
      "[430]\ttraining's multi_logloss: 0.160547\tvalid_1's multi_logloss: 0.606101\n",
      "[440]\ttraining's multi_logloss: 0.1557\tvalid_1's multi_logloss: 0.606076\n",
      "[450]\ttraining's multi_logloss: 0.151116\tvalid_1's multi_logloss: 0.606023\n",
      "[460]\ttraining's multi_logloss: 0.146819\tvalid_1's multi_logloss: 0.60607\n",
      "Early stopping, best iteration is:\n",
      "[446]\ttraining's multi_logloss: 0.152933\tvalid_1's multi_logloss: 0.60583\n",
      "0.518847465484314\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros((test_feature.shape[0], 4))\n",
    "val_preds = np.zeros((train_feature.shape[0], 4))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(train_feature, train_label):\n",
    "    xtrain, ytrain = train_feature[train_index], train_label[train_index]\n",
    "    xtest, ytest = train_feature[test_index], train_label[test_index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(xtrain, label=ytrain)\n",
    "    dvalid = lgb.Dataset(xtest, label=ytest)\n",
    "    param = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 4,\n",
    "        'metric': 'multi_logloss',\n",
    "        'early_stopping_rounds': 20,\n",
    "        'learning_rate': 0.03,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dtrain, dvalid], num_boost_round=100000, verbose_eval=10\n",
    "    )\n",
    "    \n",
    "    val_preds[test_index] = gbm.predict(xtest)\n",
    "    preds += gbm.predict(test_feature) / 5\n",
    "\n",
    "print(macro_f1(train_label, np.argmax(val_preds, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e394121",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df['label'] = np.argmax(preds, axis=1)\n",
    "submit_df[['sn', 'fault_time', 'label']].to_csv('./preliminary_pred_a.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88023da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "591271fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5090071657946984"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5090071657946984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679ad14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
