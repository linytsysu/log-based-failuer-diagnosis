{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302f29ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16604, 3) (3030, 2)\n",
      "(16604, 5) (3030, 4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "label1 = pd.read_csv('../data/preliminary_train_label_dataset.csv')\n",
    "label2 = pd.read_csv('../data/preliminary_train_label_dataset_s.csv')\n",
    "label_df = pd.concat([label1, label2]).reset_index(drop=True)\n",
    "label_df = label_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "submit_df = pd.read_csv('../data/preliminary_submit_dataset_b.csv')\n",
    "\n",
    "print(label_df.shape, submit_df.shape)\n",
    "\n",
    "log_df = pd.read_csv('../code/log_template.csv')\n",
    "log_df['msg_lower'] = log_df['msg_lower'].astype(str)\n",
    "log_df['server_model'] = log_df['server_model'].astype(str)\n",
    "\n",
    "log_df['time'] = pd.to_datetime(log_df['time'])\n",
    "label_df['fault_time'] = pd.to_datetime(label_df['fault_time'])\n",
    "submit_df['fault_time'] = pd.to_datetime(submit_df['fault_time'])\n",
    "\n",
    "log_df['time_ts'] = log_df[\"time\"].values.astype(np.int64) // 10 ** 9\n",
    "label_df['fault_time_ts'] = label_df[\"fault_time\"].values.astype(np.int64) // 10 ** 9\n",
    "submit_df['fault_time_ts'] = submit_df[\"fault_time\"].values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "crashdump_df = pd.read_csv('../data/preliminary_crashdump_dataset.csv')\n",
    "venus_df = pd.read_csv('../data/preliminary_venus_dataset.csv')\n",
    "crashdump_df['fault_time'] = pd.to_datetime(crashdump_df['fault_time'])\n",
    "venus_df['fault_time'] = pd.to_datetime(venus_df['fault_time'])\n",
    "crashdump_df['fault_time_ts'] = crashdump_df[\"fault_time\"].values.astype(np.int64) // 10 ** 9\n",
    "venus_df['fault_time_ts'] = venus_df[\"fault_time\"].values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "label_df = label_df.merge(log_df[['sn', 'server_model']].drop_duplicates(), on=['sn'], how='left')\n",
    "submit_df = submit_df.merge(log_df[['sn', 'server_model']].drop_duplicates(), on=['sn'], how='left')\n",
    "label_df = label_df.fillna('MISSING')\n",
    "submit_df = submit_df.fillna('MISSING')\n",
    "print(label_df.shape, submit_df.shape)\n",
    "\n",
    "label_cnt_df = label_df.groupby('label').size().reset_index().rename({0: 'label_cnt'}, axis=1)\n",
    "label_model_cnt_df = label_df.groupby(['server_model', 'label']).size().reset_index()\\\n",
    "    .rename({0: 'label_model_cnt'}, axis=1)\n",
    "label_model_cnt_df = label_model_cnt_df.merge(label_cnt_df, on='label', how='left')\n",
    "label_model_cnt_df['model/label'] = label_model_cnt_df['label_model_cnt'] / label_model_cnt_df['label_cnt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c7b0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=16, random_state=42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safe_split(strs, n, sep='|'):\n",
    "    str_li = strs.split(sep)\n",
    "    if len(str_li) >= n + 1:\n",
    "        return str_li[n].strip()\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "log_df['time_gap'] = log_df['time'].dt.ceil('30T')\n",
    "log_df['msg_split_0'] = log_df['msg_lower'].apply(lambda x: safe_split(x, 0))\n",
    "log_df['msg_split_1'] = log_df['msg_lower'].apply(lambda x: safe_split(x, 1))\n",
    "log_df['msg_split_2'] = log_df['msg_lower'].apply(lambda x: safe_split(x, 2))\n",
    "\n",
    "sentences_list = list()\n",
    "for info, group in log_df.groupby(['sn', 'time_gap']):\n",
    "    group = group.sort_values(by='time')\n",
    "    sentences_list.append(\"\\n\".join(group['msg_lower'].values.astype(str)))\n",
    "\n",
    "sentences = list()\n",
    "for s in sentences_list:\n",
    "    sentences.append([w for w in s.split()])\n",
    "\n",
    "w2v_model = Word2Vec(sentences, vector_size=64, window=3, min_count=2, sg=0, hs=1, workers=1, seed=2022)\n",
    "\n",
    "tfv = TfidfVectorizer(ngram_range=(1,3), min_df=5, max_features=50000)\n",
    "tfv.fit(sentences_list)\n",
    "X_tfidf = tfv.transform(sentences_list)\n",
    "svd = TruncatedSVD(n_components=16, random_state=42)\n",
    "svd.fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450c3ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47239, 3118)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b445bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import SparsePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a91c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = SparsePCA(n_components=16, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c5d564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yitinglin/Projects/log-based-failuer-diagnosis/env/lib/python3.7/site-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparsePCA(n_components=16, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_tfidf.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c67b48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a37ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_pca(sentence, n_components=16):\n",
    "    X_tfidf = tfv.transform(sentence)\n",
    "    X_svd = svd.transform(X_tfidf.todense())\n",
    "    return X_svd\n",
    "\n",
    "def get_tfidf_pac_feature(df):\n",
    "    vec = get_tfidf_pca(['\\n'.join(df['msg_lower'].values.astype(str))])[0]\n",
    "    data = {}\n",
    "    for i in range(16):\n",
    "        data['pca_%d'%i] = vec[i]\n",
    "    return data\n",
    "\n",
    "def make_dataset(dataset, data_type='train'):\n",
    "    ret = []\n",
    "    for idx in tqdm(range(dataset.shape[0])):\n",
    "        row = dataset.iloc[idx]\n",
    "        sn = row['sn']\n",
    "        fault_time = row['fault_time']\n",
    "        fault_time_ts = row['fault_time_ts']\n",
    "        server_model = row['server_model']\n",
    "        sub_log = log_df[(log_df['sn'] == sn) & (log_df['time_ts'] <= fault_time_ts)]\n",
    "        sub_log = sub_log.sort_values(by='time')\n",
    "        last_msg_id = str(sub_log['msg_id'].values[-1]) if sub_log.shape[0] > 0 else 'NULL'\n",
    "        last_template_id = str(sub_log['template_id'].values[-1]) if sub_log.shape[0] > 0 else 'NULL'\n",
    "        data = {\n",
    "            'sn': sn,\n",
    "            'fault_time': fault_time,\n",
    "        }\n",
    "        # df_tmp1 = sub_log[sub_log['time_ts'] - fault_time_ts >= -60 * 60 * 2]\n",
    "        df_tmp1 = sub_log.tail(20)\n",
    "        df_tmp2 = sub_log.tail(50)\n",
    "\n",
    "        data_tmp = get_tfidf_pac_feature(df_tmp1)\n",
    "        data.update(data_tmp)\n",
    "\n",
    "        if data_type == 'train':\n",
    "            data['label'] = row['label']\n",
    "        ret.append(data)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6c7f7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 16604/16604 [10:14<00:00, 27.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3030/3030 [01:48<00:00, 27.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train = make_dataset(label_df, data_type='train')\n",
    "df_train = pd.DataFrame(train)\n",
    "\n",
    "test = make_dataset(submit_df, data_type='test')\n",
    "df_test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d5ed7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16604, 19), (3030, 18))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "767f6918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train_pca.csv', index=False)\n",
    "df_test.to_csv('test_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ca07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
